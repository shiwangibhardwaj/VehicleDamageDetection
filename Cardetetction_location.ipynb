{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaartikaykhanduri/vehicle-damage-detection/blob/main/Cardetetction_location.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFodC-z6rjNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a35464a-9060-4175-cbd4-016c98581d61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FmlFpy1EX7Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeZ5-JbLryuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0858080c-438d-4926-93ed-2e5414707ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/gdrive/MyDrive/car-damage-dataset.zip\n",
            "replace car-damage-dataset/data1/training/damage/0001.JPEG? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip \"/content/gdrive/MyDrive/car-damage-dataset.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic-VaF_3r5Ld"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import h5py\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from IPython.display import Image, display, clear_output\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style('whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuOGmyFxr_US"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Activation, Dropout, Flatten, Dense, Input\n",
        "from keras.regularizers import l2, l1\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import array_to_img, img_to_array,load_img\n",
        "from keras.callbacks import ModelCheckpoint, History\n",
        "from keras import backend as K\n",
        "from keras.utils.data_utils import get_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81KQXZEHsHMN"
      },
      "outputs": [],
      "source": [
        "def save_bottleneck_features():\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    model = VGG16(include_top=False, weights='imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(train_data_dir, target_size=(img_width,img_height), batch_size=batch_size, class_mode=None, shuffle=False)\n",
        "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples//batch_size)\n",
        "    np.save(location+'/bottleneck_features_train.npy', bottleneck_features_train)\n",
        "\n",
        "    generator = datagen.flow_from_directory(validation_data_dir, target_size=(img_width,img_height), batch_size=batch_size, class_mode=None, shuffle=False)\n",
        "    bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples//batch_size)\n",
        "    np.save(location+'/bottleneck_features_validation.npy', bottleneck_features_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPwf5CkNsRPq"
      },
      "outputs": [],
      "source": [
        "def print_best_model_results(model_hist):\n",
        "    best_epoch = np.argmax(model_hist['val_accuracy'])\n",
        "    print('epoch:', best_epoch+1, ', val_accuracy:', model_hist['val_accuracy'][best_epoch], ', val_loss:', model_hist['val_loss'][best_epoch])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2orOJ1jsYZl"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(hist, stop=50):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    axes[0].plot(range(stop), hist['accuracy'], label='Training')\n",
        "    axes[0].plot(range(stop), hist['val_accuracy'], label='Validation')\n",
        "    axes[0].set_title('Accuracy')\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].legend(loc='lower right')\n",
        "\n",
        "    axes[1].plot(range(stop), hist['loss'], label='Training')\n",
        "    axes[1].plot(range(stop), hist['val_loss'], label='Validation')\n",
        "    axes[1].set_title('Loss')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout();\n",
        "\n",
        "    print(\"Best Model:\")\n",
        "    print_best_model_results(hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLsl6bfUsaiF"
      },
      "outputs": [],
      "source": [
        "def train_categorical_model():\n",
        "    train_data = np.load(location+'/bottleneck_features_train.npy')\n",
        "    train_labels = np.array([0]*(416) + [1]*(288) + [2]*(272))\n",
        "    train_labels = to_categorical(train_labels)\n",
        "\n",
        "    validation_data = np.load(location+'/bottleneck_features_validation.npy')\n",
        "    validation_labels = np.array([0]*(73) + [1]*(53) + [2]*(50))\n",
        "    validation_labels = to_categorical(validation_labels)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    checkpoint = ModelCheckpoint(top_model_weights_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True,mode='auto')\n",
        "\n",
        "    fit = model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(validation_data,validation_labels), callbacks=[checkpoint])\n",
        "\n",
        "    with open(location+'/top_history.txt', 'w') as f:\n",
        "        json.dump(fit.history, f)\n",
        "\n",
        "    return model,fit.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLSAcllGsgMY"
      },
      "outputs": [],
      "source": [
        "def finetune_categorical_model():\n",
        "    input_tensor = Input(shape=(256,256,3))\n",
        "    base_model = VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "    print(\"Model loaded.\")\n",
        "    top_model = Sequential()\n",
        "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "    top_model.add(Dense(256, activation='relu'))\n",
        "    top_model.add(Dropout(0.5))\n",
        "    top_model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    top_model.load_weights(top_model_weights_path)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
        "\n",
        "    for layer in model.layers[:25]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.00001, momentum=0.9), metrics=['accuracy'])\n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
        "\n",
        "    validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
        "\n",
        "    checkpoint = ModelCheckpoint(fine_tuned_model_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
        "\n",
        "    fit = model.fit(train_generator, steps_per_epoch=nb_train_samples//batch_size, epochs=epochs, validation_data=validation_generator, validation_steps=nb_validation_samples//batch_size, verbose=1, callbacks=[checkpoint])\n",
        "\n",
        "    with open(location+'/ft_history.txt', 'w') as f:\n",
        "        json.dump(fit.history, f)\n",
        "\n",
        "    return model, fit.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwtQxKmIsjd_"
      },
      "outputs": [],
      "source": [
        "def evaluate_categorical_model(model, directory, labels):\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    generator = datagen.flow_from_directory(directory, target_size=(img_height,img_width), batch_size=batch_size, class_mode='categorical', shuffle=False)\n",
        "\n",
        "    predictions = model.predict_generator(generator, len(labels))\n",
        "\n",
        "    pred_labels = [0 if i<0.5 else 1 for i in predictions]\n",
        "\n",
        "    print('')\n",
        "    print(classification_report(validation_labels, pred_labels))\n",
        "    print('')\n",
        "    cm = confusion_matrix(validation_labels, pred_labels)\n",
        "    return cm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOCATION OF THE DAMAGE ( FRONT , SIDE , REAR)"
      ],
      "metadata": {
        "id": "bmpZ4MASqC42"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m73ZkzSMsmnV"
      },
      "outputs": [],
      "source": [
        "location = 'car-damage-dataset/data2'\n",
        "top_model_weights_path = location+'/my_model_weights.h5'\n",
        "fine_tuned_model_path = location+'/ft_model.h5'\n",
        "model1 = location+'/bottleneck_fc_model.h5'\n",
        "train_data_dir = location+'/training'\n",
        "validation_data_dir = location+'/validation'\n",
        "train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
        "nb_train_samples = 976\n",
        "validation_samples = [len(os.listdir(validation_data_dir+'/'+i)) for i in sorted(os.listdir(validation_data_dir))]\n",
        "nb_validation_samples = 176\n",
        "\n",
        "img_width, img_height = 256,256\n",
        "epochs = 1\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObMlTn1ds3YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4436d749-4672-444d-ea43-654a1a52f963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 985 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-670539d0b709>:7: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  bottleneck_features_train = model.predict_generator(generator, nb_train_samples//batch_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 179 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-670539d0b709>:11: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples//batch_size)\n"
          ]
        }
      ],
      "source": [
        "save_bottleneck_features()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d3_model, d3_history = train_categorical_model()"
      ],
      "metadata": {
        "id": "C-4BJOCDo2vP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc77ca2a-2a8b-447f-86a3-9b6c7679aed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61/61 [==============================] - ETA: 0s - loss: 3.9601 - accuracy: 0.4191\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48864, saving model to car-damage-dataset/data2/my_model_weights.h5\n",
            "61/61 [==============================] - 8s 118ms/step - loss: 3.9601 - accuracy: 0.4191 - val_loss: 1.0463 - val_accuracy: 0.4886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d3_model.save('my_model_weights.h5')\n",
        "d3_model.save('ft_model.h5')"
      ],
      "metadata": {
        "id": "T3BuZlBCW4Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxjpVqSl9Ymy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e6d034-e23d-41d1-b215-f3903de1caa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Found 985 images belonging to 3 classes.\n",
            "Found 179 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61/61 [==============================] - ETA: 0s - loss: 1.0502 - accuracy: 0.4892 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.48295, saving model to car-damage-dataset/data2/ft_model.h5\n",
            "61/61 [==============================] - 858s 14s/step - loss: 1.0502 - accuracy: 0.4892 - val_loss: 1.0522 - val_accuracy: 0.4830\n"
          ]
        }
      ],
      "source": [
        "ft_model, ft_history = finetune_categorical_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3OzJrhyzhPq"
      },
      "outputs": [],
      "source": [
        "def pipelocation(image_path, model):\n",
        "    urllib.request.urlretrieve(image_path, 'save.jpg')\n",
        "    img = load_img('save.jpg', target_size=(256,256))\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,)+x.shape)/255\n",
        "    pred = model.predict(x)\n",
        "    pred_labels = np.argmax(pred, axis=1)\n",
        "    d = {0:'Front', 1:'Rear', 2:'Side'}\n",
        "    for key in d.keys():\n",
        "        if pred_labels[0] == key:\n",
        "            print(\"Validating location of damage....Result:\",d[key])\n",
        "            return d[key]\n",
        "    print(\"Severity assessment complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipelocation(\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT4DEd3yM1SERRZkPl25MZGIIxtl127-R8IrQ&usqp=CAU\",ft_model)"
      ],
      "metadata": {
        "id": "UIPpA0UtmpNt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e39db608-a630-4e58-8e85-f532e8047ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 818ms/step\n",
            "Validating location of damage....Result: Front\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Front'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HOW MUCH DAMAGE (MINOR , MODERATE , SEVERE)"
      ],
      "metadata": {
        "id": "zrQLY8xDp0RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "location = 'car-damage-dataset/data3'\n",
        "top_model_weights_path = location+'/my_model_weights.h5'\n",
        "fine_tuned_model_path = location+'/ft_model.h5'\n",
        "model1 = location+'/bottleneck_fc_model.h5'\n",
        "train_data_dir = location+'/training'\n",
        "validation_data_dir = location+'/validation'\n",
        "train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
        "nb_train_samples = 976\n",
        "validation_samples = [len(os.listdir(validation_data_dir+'/'+i)) for i in sorted(os.listdir(validation_data_dir))]\n",
        "nb_validation_samples = 176\n",
        "\n",
        "img_width, img_height = 256,256\n",
        "epochs = 1\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "Zgh4SeJFn395"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_bottleneck_features()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfMnAOu7oi4d",
        "outputId": "a7d6e9ce-fc92-4598-92d4-b905c8acb8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 979 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-670539d0b709>:7: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  bottleneck_features_train = model.predict_generator(generator, nb_train_samples//batch_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 176 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-670539d0b709>:11: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples//batch_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2_model, d2_history = train_categorical_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GMymXcWonrZ",
        "outputId": "66a2e3e0-9f80-4b47-9031-a961592d0e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61/61 [==============================] - ETA: 0s - loss: 4.1823 - accuracy: 0.4580\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47727, saving model to car-damage-dataset/data3/my_model_weights.h5\n",
            "61/61 [==============================] - 7s 106ms/step - loss: 4.1823 - accuracy: 0.4580 - val_loss: 0.9832 - val_accuracy: 0.4773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2_model.save('my_model_weights.h5')\n",
        "d2_model.save('ft_model.h5')"
      ],
      "metadata": {
        "id": "fHSEOXIqpA5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft2_model, ft2_history = finetune_categorical_model()"
      ],
      "metadata": {
        "id": "6XZaC2v8pGXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972b47b3-0ab4-4907-bbcd-a9dc3560c707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "Found 979 images belonging to 3 classes.\n",
            "Found 176 images belonging to 3 classes.\n",
            "61/61 [==============================] - ETA: 0s - loss: 1.1147 - accuracy: 0.3586 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.31818, saving model to car-damage-dataset/data3/ft_model.h5\n",
            "61/61 [==============================] - 864s 14s/step - loss: 1.1147 - accuracy: 0.3586 - val_loss: 1.1008 - val_accuracy: 0.3182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pipedquality(image_path, model):\n",
        "    urllib.request.urlretrieve(image_path, 'save.jpg')\n",
        "    img = load_img('save.jpg', target_size=(256,256))\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,)+x.shape)/255\n",
        "    pred = model.predict(x)\n",
        "    pred_labels = np.argmax(pred, axis=1)\n",
        "    d = {0:'minor', 1:'moderate', 2:'Severe'}\n",
        "    for key in d.keys():\n",
        "        if pred_labels[0] == key:\n",
        "            print(\"Validating damage quantity....Result:\",d[key])\n",
        "    print(\"Damage assessment complete.\")"
      ],
      "metadata": {
        "id": "Y4qmu6trpOIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INPUT IMAGE"
      ],
      "metadata": {
        "id": "juH4OL89nVRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipedquality(\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQJCbs1451TX7QnB9bGmrmRZGi0teOB9ASREQ&usqp=CAU\",ft2_model)"
      ],
      "metadata": {
        "id": "RhaWHtd3qRUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8f216a-c602-49bb-d103-b18d30fda85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 796ms/step\n",
            "Validating damage quantity....Result: minor\n",
            "Damage assessment complete.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}